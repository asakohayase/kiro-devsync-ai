"""Sophisticated message batching system for grouped notifications."""

import time
import hashlib
from typing import Dict, List, Any, Optional, Tuple, Set, Callable
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from enum import Enum
from collections import defaultdict
import logging

from .message_formatter import SlackMessage, TemplateConfig
from .interactive_elements import InteractiveElementBuilder, default_interactive_builder


class BatchType(Enum):
    """Types of message batches."""
    DAILY_SUMMARY = "daily_summary"
    SPRINT_UPDATE = "sprint_update"
    PR_ACTIVITY = "pr_activity"
    JIRA_ACTIVITY = "jira_activity"
    ALERT_DIGEST = "alert_digest"
    WEEKLY_CHANGELOG = "weekly_changelog"
    TEAM_ACTIVITY = "team_activity"
    CUSTOM = "custom"


class BatchStrategy(Enum):
    """Batching strategies."""
    TIME_BASED = "time_based"
    CONTENT_SIMILARITY = "content_similarity"
    AUTHOR_BASED = "author_based"
    PRIORITY_BASED = "priority_based"
    MIXED = "mixed"


class ContentType(Enum):
    """Content types for similarity detection."""
    PR_UPDATE = "pr_update"
    JIRA_UPDATE = "jira_update"
    ALERT = "alert"
    STANDUP = "standup"
    DEPLOYMENT = "deployment"
    BLOCKER = "blocker"


@dataclass
class BatchableMessage:
    """A message that can be batched with others."""
    id: str
    content_type: ContentType
    timestamp: datetime
    author: Optional[str] = None
    priority: str = "medium"
    data: Dict[str, Any] = field(default_factory=dict)
    metadata: Dict[str, Any] = field(default_factory=dict)
    
    def get_similarity_key(self) -> str:
        """Generate key for content similarity grouping."""
        key_parts = [
            self.content_type.value,
            self.author or "unknown",
            self.data.get('repository', ''),
            self.data.get('project', ''),
            self.data.get('team', '')
        ]
        return ":".join(str(part).lower() for part in key_parts)
    
    def get_priority_score(self) -> int:
        """Get numeric priority score for ordering."""
        priority_scores = {
            'critical': 100,
            'high': 75,
            'medium': 50,
            'low': 25,
            'lowest': 10
        }
        return priority_scores.get(self.priority.lower(), 50)


@dataclass
class BatchGroup:
    """A group of related messages to be batched."""
    id: str
    channel_id: str
    batch_type: BatchType
    messages: List[BatchableMessage] = field(default_factory=list)
    created_at: datetime = field(default_factory=datetime.now)
    expires_at: Optional[datetime] = None
    last_activity: datetime = field(default_factory=datetime.now)
    metadata: Dict[str, Any] = field(default_factory=dict)
    
    def add_message(self, message: BatchableMessage) -> None:
        """Add message to batch group."""
        self.messages.append(message)
        # Update expiration based on newest message
        if not self.expires_at or message.timestamp > self.expires_at:
            self.expires_at = message.timestamp + timedelta(minutes=5)
        # Update last activity timestamp
        self.last_activity = datetime.now()
    
    def get_summary_stats(self) -> Dict[str, Any]:
        """Get summary statistics for the batch."""
        stats = {
            'total_count': len(self.messages),
            'content_types': defaultdict(int),
            'authors': set(),
            'priority_counts': defaultdict(int),
            'time_range': {
                'start': min(msg.timestamp for msg in self.messages) if self.messages else None,
                'end': max(msg.timestamp for msg in self.messages) if self.messages else None
            }
        }
        
        for msg in self.messages:
            stats['content_types'][msg.content_type.value] += 1
            if msg.author:
                stats['authors'].add(msg.author)
            stats['priority_counts'][msg.priority] += 1
        
        stats['authors'] = list(stats['authors'])
        return stats
    
    def should_flush(self, max_age_minutes: int = 5, max_size: int = 5) -> bool:
        """Check if batch should be flushed."""
        if len(self.messages) >= max_size:
            return True
        
        if self.expires_at and datetime.now() >= self.expires_at:
            return True
        
        age_minutes = (datetime.now() - self.created_at).total_seconds() / 60
        return age_minutes >= max_age_minutes


@dataclass
class ChannelStats:
    """Statistics for a specific channel."""
    channel_id: str
    batches_created: int = 0
    batches_sent: int = 0
    messages_batched: int = 0
    average_batch_size: float = 0.0
    average_time_to_send: float = 0.0
    last_activity: Optional[datetime] = None
    active_batch_count: int = 0
    pending_message_count: int = 0
    
    def update_batch_created(self) -> None:
        """Update statistics when a new batch is created."""
        self.batches_created += 1
        self.active_batch_count += 1
        self.last_activity = datetime.now()
    
    def update_message_added(self, message_count: int = 1) -> None:
        """Update statistics when messages are added to batches."""
        self.messages_batched += message_count
        self.pending_message_count += message_count
        self.last_activity = datetime.now()
    
    def update_batch_sent(self, message_count: int, time_to_send_minutes: float) -> None:
        """Update statistics when a batch is sent."""
        self.batches_sent += 1
        self.active_batch_count = max(0, self.active_batch_count - 1)
        self.pending_message_count = max(0, self.pending_message_count - message_count)
        self.last_activity = datetime.now()
        
        # Update averages using incremental calculation
        if self.batches_sent == 1:
            self.average_batch_size = float(message_count)
            self.average_time_to_send = time_to_send_minutes
        else:
            # Incremental average calculation
            n = self.batches_sent
            self.average_batch_size = ((n - 1) * self.average_batch_size + message_count) / n
            self.average_time_to_send = ((n - 1) * self.average_time_to_send + time_to_send_minutes) / n
    
    def get_efficiency_metrics(self) -> Dict[str, float]:
        """Get efficiency metrics for the channel."""
        total_batches = self.batches_created
        if total_batches == 0:
            return {
                'batch_completion_rate': 0.0,
                'messages_per_batch': 0.0,
                'batching_efficiency': 0.0
            }
        
        completion_rate = self.batches_sent / total_batches
        messages_per_batch = self.messages_batched / total_batches if total_batches > 0 else 0.0
        
        # Efficiency score based on batch size and completion rate
        efficiency = completion_rate * min(messages_per_batch / 3.0, 1.0)  # Optimal around 3 messages per batch
        
        return {
            'batch_completion_rate': completion_rate,
            'messages_per_batch': messages_per_batch,
            'batching_efficiency': efficiency
        }


@dataclass
class BatchConfig:
    """Configuration for message batching."""
    enabled: bool = True
    max_batch_size: int = 5
    max_batch_age_minutes: int = 5
    similarity_threshold: float = 0.7
    enable_pagination: bool = True
    items_per_page: int = 5
    enable_threading: bool = True
    priority_ordering: bool = True
    strategies: List[BatchStrategy] = field(default_factory=lambda: [BatchStrategy.TIME_BASED, BatchStrategy.CONTENT_SIMILARITY])


class MessageBatcher:
    """Sophisticated message batching system."""
    
    def __init__(self, config: Optional[BatchConfig] = None, formatter_factory=None):
        """Initialize message batcher."""
        self.config = config or BatchConfig()
        self.logger = logging.getLogger(__name__)
        
        # Channel-specific batch groups
        self._channel_batch_groups: Dict[str, Dict[str, BatchGroup]] = defaultdict(dict)
        
        # Channel-specific statistics
        self._channel_stats: Dict[str, ChannelStats] = {}
        
        # Enhanced global batch statistics
        self._stats = {
            'batches_created': 0,
            'messages_batched': 0,
            'batches_flushed': 0,
            'similarity_matches': 0,
            'channels_active': 0,
            'batches_by_channel': defaultdict(int),
            'batches_by_type': defaultdict(int),
            'total_processing_time_seconds': 0.0,
            'average_batch_processing_time': 0.0,
            'peak_concurrent_batches': 0,
            'memory_usage_mb': 0.0,
            'error_count': 0,
            'last_activity': None,
            'system_start_time': datetime.now()
        }
        
        # Interactive element builder for batch messages
        self._interactive_builder = default_interactive_builder
        
        # SlackMessageFormatterFactory integration
        self._formatter_factory = formatter_factory
        
        self.logger.info("MessageBatcher initialized")
    
    def _get_or_create_channel_stats(self, channel_id: str) -> ChannelStats:
        """Get or create channel statistics."""
        if channel_id not in self._channel_stats:
            self._channel_stats[channel_id] = ChannelStats(channel_id=channel_id)
        return self._channel_stats[channel_id]
    
    def add_message(self, message: BatchableMessage, channel_id: str = "default") -> Optional[SlackMessage]:
        """Add message to batching system. Returns batched message if ready."""
        if not self.config.enabled:
            return None
        
        # Get or create channel stats
        channel_stats = self._get_or_create_channel_stats(channel_id)
        
        # Find or create appropriate batch group for the channel
        batch_group = self._find_or_create_batch_group(message, channel_id)
        batch_group.add_message(message)
        
        # Update statistics
        self._stats['messages_batched'] += 1
        self._stats['batches_by_channel'][channel_id] += 1
        self._stats['last_activity'] = datetime.now()
        channel_stats.update_message_added(1)
        
        # Check if batch should be flushed
        if batch_group.should_flush(self.config.max_batch_age_minutes, self.config.max_batch_size):
            return self._flush_batch_group(batch_group, channel_id)
        
        return None
    
    def flush_all_batches(self) -> List[SlackMessage]:
        """Flush all pending batch groups across all channels."""
        batched_messages = []
        
        for channel_id in list(self._channel_batch_groups.keys()):
            channel_batches = self.flush_channel_batches(channel_id)
            batched_messages.extend(channel_batches)
        
        return batched_messages
    
    def flush_channel_batches(self, channel_id: str) -> List[SlackMessage]:
        """Flush all pending batch groups for a specific channel."""
        batched_messages = []
        
        if channel_id not in self._channel_batch_groups:
            return batched_messages
        
        channel_groups = self._channel_batch_groups[channel_id]
        for group_id in list(channel_groups.keys()):
            batch_group = channel_groups[group_id]
            if batch_group.messages:  # Only flush non-empty batches
                batched_message = self._flush_batch_group(batch_group, channel_id)
                if batched_message:
                    batched_messages.append(batched_message)
        
        return batched_messages
    
    def flush_expired_batches(self) -> List[SlackMessage]:
        """Flush only expired batch groups across all channels."""
        batched_messages = []
        current_time = datetime.now()
        
        for channel_id in list(self._channel_batch_groups.keys()):
            channel_groups = self._channel_batch_groups[channel_id]
            for group_id in list(channel_groups.keys()):
                batch_group = channel_groups[group_id]
                if batch_group.should_flush(self.config.max_batch_age_minutes, self.config.max_batch_size):
                    batched_message = self._flush_batch_group(batch_group, channel_id)
                    if batched_message:
                        batched_messages.append(batched_message)
        
        return batched_messages
    
    def get_batch_stats(self) -> Dict[str, Any]:
        """Get batching statistics."""
        # Calculate active batches and pending messages from channel-specific data
        active_batches = sum(len(channel_groups) for channel_groups in self._channel_batch_groups.values())
        pending_messages = 0
        for channel_groups in self._channel_batch_groups.values():
            for group in channel_groups.values():
                pending_messages += len(group.messages)
        
        return {
            **self._stats,
            'active_batches': active_batches,
            'pending_messages': pending_messages
        }
    
    def get_channel_stats(self, channel_id: str) -> Optional[ChannelStats]:
        """Get statistics for specific channel."""
        if channel_id not in self._channel_stats:
            return None
        
        # Update real-time counts before returning
        channel_stats = self._channel_stats[channel_id]
        
        # Update active batch count and pending message count from current state
        if channel_id in self._channel_batch_groups:
            channel_groups = self._channel_batch_groups[channel_id]
            channel_stats.active_batch_count = len(channel_groups)
            channel_stats.pending_message_count = sum(
                len(group.messages) for group in channel_groups.values()
            )
        else:
            channel_stats.active_batch_count = 0
            channel_stats.pending_message_count = 0
        
        return channel_stats
    
    def get_all_channel_stats(self) -> Dict[str, ChannelStats]:
        """Get statistics for all channels."""
        stats = {}
        for channel_id in self._channel_stats:
            stats[channel_id] = self.get_channel_stats(channel_id)
        return stats
    
    def _find_or_create_batch_group(self, message: BatchableMessage, channel_id: str) -> BatchGroup:
        """Find existing batch group or create new one for message in specific channel."""
        channel_groups = self._channel_batch_groups[channel_id]
        
        # Try different strategies to find matching batch within channel boundaries
        for strategy in self.config.strategies:
            group_key = self._get_group_key(message, strategy, channel_id)
            
            if group_key in channel_groups:
                existing_group = channel_groups[group_key]
                
                # Verify the group belongs to the correct channel
                if existing_group.channel_id == channel_id:
                    # Check if message fits in existing group (similarity detection within channel)
                    if self._can_add_to_group(message, existing_group, strategy):
                        return existing_group
        
        # Create new batch group for this channel
        return self._create_new_batch_group(message, channel_id)
    
    def _get_group_key(self, message: BatchableMessage, strategy: BatchStrategy, channel_id: str) -> str:
        """Generate group key based on batching strategy with channel context."""
        # Include channel_id in all group keys to ensure channel isolation
        channel_prefix = f"ch_{channel_id}"
        
        if strategy == BatchStrategy.TIME_BASED:
            # Group by 5-minute time windows within channel
            time_window = int(message.timestamp.timestamp() // 300) * 300
            return f"{channel_prefix}_time_{time_window}_{message.content_type.value}"
        
        elif strategy == BatchStrategy.CONTENT_SIMILARITY:
            return f"{channel_prefix}_similarity_{message.get_similarity_key()}"
        
        elif strategy == BatchStrategy.AUTHOR_BASED:
            author = message.author or "unknown"
            return f"{channel_prefix}_author_{author}_{message.content_type.value}"
        
        elif strategy == BatchStrategy.PRIORITY_BASED:
            return f"{channel_prefix}_priority_{message.priority}_{message.content_type.value}"
        
        else:  # MIXED strategy
            similarity_key = message.get_similarity_key()
            time_window = int(message.timestamp.timestamp() // 300) * 300
            return f"{channel_prefix}_mixed_{similarity_key}_{time_window}"
    
    def _can_add_to_group(self, message: BatchableMessage, group: BatchGroup, strategy: BatchStrategy) -> bool:
        """Check if message can be added to existing group within channel boundaries."""
        # Verify group belongs to the same channel (additional safety check)
        if hasattr(group, 'channel_id') and group.channel_id:
            # This ensures we're only comparing within the same channel
            pass
        
        # Check size limit
        if len(group.messages) >= self.config.max_batch_size:
            return False
        
        # Check age limit
        age_minutes = (datetime.now() - group.created_at).total_seconds() / 60
        if age_minutes >= self.config.max_batch_age_minutes:
            return False
        
        # Strategy-specific checks within channel context
        if strategy == BatchStrategy.CONTENT_SIMILARITY:
            # Calculate similarity only within the same channel
            return self._calculate_similarity(message, group) >= self.config.similarity_threshold
        
        elif strategy == BatchStrategy.TIME_BASED:
            # For time-based batching, ensure messages are within the same time window
            if group.messages:
                latest_message = max(group.messages, key=lambda m: m.timestamp)
                time_diff_minutes = abs((message.timestamp - latest_message.timestamp).total_seconds() / 60)
                return time_diff_minutes <= self.config.max_batch_age_minutes
        
        elif strategy == BatchStrategy.AUTHOR_BASED:
            # For author-based batching, ensure same author and content type
            if group.messages:
                first_message = group.messages[0]
                return (message.author == first_message.author and 
                       message.content_type == first_message.content_type)
        
        elif strategy == BatchStrategy.PRIORITY_BASED:
            # For priority-based batching, ensure same priority and content type
            if group.messages:
                first_message = group.messages[0]
                return (message.priority == first_message.priority and 
                       message.content_type == first_message.content_type)
        
        return True
    
    def _calculate_similarity(self, message: BatchableMessage, group: BatchGroup) -> float:
        """Calculate content similarity between message and group."""
        if not group.messages:
            return 1.0
        
        # Simple similarity based on content type, author, and project
        similarities = []
        
        for existing_msg in group.messages:
            similarity = 0.0
            
            # Content type match (40% weight)
            if message.content_type == existing_msg.content_type:
                similarity += 0.4
            
            # Author match (30% weight)
            if message.author and message.author == existing_msg.author:
                similarity += 0.3
            
            # Project/repository match (30% weight)
            msg_project = message.data.get('repository') or message.data.get('project', '')
            existing_project = existing_msg.data.get('repository') or existing_msg.data.get('project', '')
            if msg_project and msg_project == existing_project:
                similarity += 0.3
            
            similarities.append(similarity)
        
        return max(similarities) if similarities else 0.0
    
    def _create_new_batch_group(self, message: BatchableMessage, channel_id: str) -> BatchGroup:
        """Create new batch group for message in specific channel."""
        # Check if this is a new channel (before accessing it)
        was_new_channel = channel_id not in self._channel_batch_groups or len(self._channel_batch_groups[channel_id]) == 0
        
        # Determine batch type based on content
        batch_type = self._determine_batch_type(message)
        
        # Calculate total batches across all channels for unique ID
        total_batches = sum(len(channel_groups) for channel_groups in self._channel_batch_groups.values())
        
        # Generate unique group ID
        group_id = f"{batch_type.value}_{int(time.time())}_{total_batches}"
        
        # Use the primary strategy to determine the storage key
        primary_strategy = self.config.strategies[0] if self.config.strategies else BatchStrategy.TIME_BASED
        group_key = self._get_group_key(message, primary_strategy, channel_id)
        
        batch_group = BatchGroup(
            id=group_id,
            channel_id=channel_id,
            batch_type=batch_type,
            metadata={
                'primary_content_type': message.content_type.value,
                'primary_author': message.author,
                'created_by_strategy': primary_strategy.value,
                'storage_key': group_key  # Store the key used for lookup
            }
        )
        
        # Store in channel-specific dictionary using the strategy-based group key
        self._channel_batch_groups[channel_id][group_key] = batch_group
        self._stats['batches_created'] += 1
        
        # Update channel statistics
        channel_stats = self._get_or_create_channel_stats(channel_id)
        channel_stats.update_batch_created()
        
        # Update channel count if this was a new channel
        if was_new_channel:
            self._stats['channels_active'] += 1
        
        return batch_group
    
    def _determine_batch_type(self, message: BatchableMessage) -> BatchType:
        """Determine appropriate batch type for message."""
        content_type_mapping = {
            ContentType.PR_UPDATE: BatchType.PR_ACTIVITY,
            ContentType.JIRA_UPDATE: BatchType.JIRA_ACTIVITY,
            ContentType.ALERT: BatchType.ALERT_DIGEST,
            ContentType.STANDUP: BatchType.DAILY_SUMMARY,
            ContentType.DEPLOYMENT: BatchType.DAILY_SUMMARY,
            ContentType.BLOCKER: BatchType.ALERT_DIGEST
        }
        
        return content_type_mapping.get(message.content_type, BatchType.DAILY_SUMMARY)
    def _flush_batch_group(self, batch_group: BatchGroup, channel_id: str) -> Optional[SlackMessage]:
        """Flush batch group and create batched message with proper cleanup."""
        if not batch_group.messages:
            self.logger.debug(f"Attempted to flush empty batch group {batch_group.id} from channel {channel_id}")
            return None
        
        # Store original state for rollback if needed
        original_message_count = len(batch_group.messages)
        batch_id = batch_group.id
        storage_key = batch_group.metadata.get('storage_key')
        cleanup_successful = False
        
        try:
            # Calculate time to send for statistics
            time_to_send_minutes = (datetime.now() - batch_group.created_at).total_seconds() / 60
            message_count = len(batch_group.messages)
            
            # Create batched message first (before cleanup) to ensure we can recover if needed
            batched_message = self._create_batched_message(batch_group)
            
            # Remove from active batches in the correct channel using the storage key
            if channel_id in self._channel_batch_groups and storage_key:
                if storage_key in self._channel_batch_groups[channel_id]:
                    try:
                        del self._channel_batch_groups[channel_id][storage_key]
                        cleanup_successful = True
                        self.logger.debug(f"Successfully removed batch group {batch_id} from channel {channel_id}")
                    except KeyError as e:
                        self.logger.warning(f"Batch group {batch_id} not found in channel {channel_id} storage: {e}")
                        # Continue processing even if removal fails
                        cleanup_successful = True
                else:
                    self.logger.warning(f"Storage key {storage_key} not found in channel {channel_id}")
                    cleanup_successful = True  # Not an error if already removed
                
                # Clean up empty channel dictionaries to prevent memory leaks
                try:
                    if not self._channel_batch_groups[channel_id]:
                        del self._channel_batch_groups[channel_id]
                        if hasattr(self, '_stats') and 'channels_active' in self._stats:
                            self._stats['channels_active'] = max(0, self._stats['channels_active'] - 1)
                        elif hasattr(self, '_global_stats') and 'channels_active' in self._global_stats:
                            self._global_stats['channels_active'] = max(0, self._global_stats['channels_active'] - 1)
                        self.logger.debug(f"Cleaned up empty channel dictionary for {channel_id}")
                except KeyError:
                    # Channel already cleaned up
                    pass
            else:
                self.logger.warning(f"Channel {channel_id} not found in batch groups or missing storage key")
                cleanup_successful = True  # Not a critical error
            
            # Update both channel and global statistics
            try:
                # Update channel statistics
                if channel_id in self._channel_stats:
                    self._channel_stats[channel_id].update_batch_sent(message_count, time_to_send_minutes)
                else:
                    self.logger.warning(f"Channel stats not found for {channel_id}")
                
                # Update global statistics - handle both _stats and _global_stats attributes
                if hasattr(self, '_stats'):
                    self._stats['batches_flushed'] += 1
                    if 'batches_by_channel' in self._stats:
                        self._stats['batches_by_channel'][channel_id] = max(0, self._stats['batches_by_channel'].get(channel_id, 1) - 1)
                    
                    # Update batch type statistics
                    batch_type_key = batch_group.batch_type.value
                    if 'batches_by_type' in self._stats:
                        self._stats['batches_by_type'][batch_type_key] = max(0, self._stats['batches_by_type'].get(batch_type_key, 1) - 1)
                
                if hasattr(self, '_global_stats'):
                    self._global_stats['batches_flushed'] += 1
                    processing_time = time_to_send_minutes * 60  # Convert to seconds
                    self._global_stats['total_processing_time_seconds'] = self._global_stats.get('total_processing_time_seconds', 0) + processing_time
                    if self._global_stats['batches_flushed'] > 0:
                        self._global_stats['average_batch_processing_time'] = (
                            self._global_stats['total_processing_time_seconds'] / self._global_stats['batches_flushed']
                        )
                    self._global_stats['last_activity'] = datetime.now()
                    
            except Exception as stats_error:
                self.logger.error(f"Failed to update statistics for batch {batch_id}: {stats_error}")
                # Don't fail the entire operation for statistics errors
            
            # Memory cleanup - clear batch group data to prevent leaks
            try:
                # Clear message references to help with garbage collection
                if hasattr(batch_group.messages, 'clear'):
                    batch_group.messages.clear()
                else:
                    # Fallback for read-only lists
                    batch_group.messages[:] = []
                
                if hasattr(batch_group.metadata, 'clear'):
                    batch_group.metadata.clear()
                else:
                    # Fallback for read-only dicts
                    for key in list(batch_group.metadata.keys()):
                        del batch_group.metadata[key]
                
                # Set references to None to help garbage collector
                batch_group.expires_at = None
            except Exception as cleanup_error:
                self.logger.warning(f"Failed to perform memory cleanup for batch {batch_id}: {cleanup_error}")
                # Don't fail for cleanup errors
            
            self.logger.info(f"Successfully flushed batch group {batch_id} with {message_count} messages from channel {channel_id} "
                           f"(time_to_send: {time_to_send_minutes:.2f} minutes)")
            
            return batched_message
            
        except Exception as e:
            self.logger.error(f"Failed to flush batch group {batch_id} from channel {channel_id}: {e}", exc_info=True)
            
            # Attempt recovery - ensure batch group is still accessible if message creation failed
            try:
                if (cleanup_successful and storage_key and 
                    channel_id in self._channel_batch_groups and 
                    storage_key not in self._channel_batch_groups[channel_id]):
                    
                    # Re-add the batch group if we removed it but failed to create the message
                    self._channel_batch_groups[channel_id][storage_key] = batch_group
                    self.logger.info(f"Restored batch group {batch_id} to channel {channel_id} after flush failure")
                    
            except Exception as recovery_error:
                self.logger.error(f"Failed to recover batch group {batch_id} after flush failure: {recovery_error}")
            
            return None

    
    def _create_batched_message(self, batch_group: BatchGroup) -> SlackMessage:
        """Create Slack message from batch group."""
        stats = batch_group.get_summary_stats()
        
        # Create summary header
        header_text = self._create_summary_header(batch_group, stats)
        
        # Create message blocks
        blocks = [
            {
                "type": "header",
                "text": {
                    "type": "plain_text",
                    "text": header_text,
                    "emoji": True
                }
            }
        ]
        
        # Add summary statistics
        blocks.extend(self._create_summary_blocks(batch_group, stats))
        
        # Add expandable details (with pagination if needed)
        blocks.extend(self._create_detail_blocks(batch_group))
        
        # Add navigation/action buttons
        blocks.extend(self._create_action_blocks(batch_group))
        
        # Create fallback text
        fallback_text = self._create_fallback_text(batch_group, stats)
        
        return SlackMessage(
            blocks=blocks,
            text=fallback_text,
            metadata={
                'batch_type': batch_group.batch_type.value,
                'message_count': len(batch_group.messages),
                'batch_id': batch_group.id,
                'created_at': batch_group.created_at.isoformat(),
                'is_batched': True
            }
        )
    
    def _create_summary_header(self, batch_group: BatchGroup, stats: Dict[str, Any]) -> str:
        """Create summary header text."""
        total_count = stats['total_count']
        
        if batch_group.batch_type == BatchType.DAILY_SUMMARY:
            return f"ðŸ“Š Daily Development Summary - {total_count} updates"
        elif batch_group.batch_type == BatchType.PR_ACTIVITY:
            return f"ðŸ”„ PR Activity Summary - {total_count} updates"
        elif batch_group.batch_type == BatchType.JIRA_ACTIVITY:
            return f"ðŸ“‹ JIRA Activity Summary - {total_count} updates"
        elif batch_group.batch_type == BatchType.ALERT_DIGEST:
            return f"âš ï¸ Alert Digest - {total_count} alerts"
        elif batch_group.batch_type == BatchType.SPRINT_UPDATE:
            return f"ðŸƒ Sprint Update - {total_count} changes"
        elif batch_group.batch_type == BatchType.WEEKLY_CHANGELOG:
            return f"ðŸ“ Weekly Changelog - {total_count} items"
        else:
            return f"ðŸ“¦ Activity Summary - {total_count} updates"
    
    def _create_summary_blocks(self, batch_group: BatchGroup, stats: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Create summary statistics blocks."""
        blocks = []
        
        # Content type breakdown
        content_summary = []
        content_icons = {
            'pr_update': 'ðŸ”„',
            'jira_update': 'ðŸ“‹',
            'alert': 'âš ï¸',
            'standup': 'ðŸ‘¥',
            'deployment': 'ðŸš€',
            'blocker': 'ðŸš«'
        }
        
        for content_type, count in stats['content_types'].items():
            icon = content_icons.get(content_type, 'ðŸ“„')
            content_summary.append(f"{icon} {count} {content_type.replace('_', ' ').title()}")
        
        if content_summary:
            blocks.append({
                "type": "section",
                "text": {
                    "type": "mrkdwn",
                    "text": "\n".join([f"â”œâ”€â”€ {item}" for item in content_summary[:-1]] + [f"â””â”€â”€ {content_summary[-1]}"])
                }
            })
        
        # Author summary
        if stats['authors']:
            author_list = ", ".join(f"@{author}" for author in stats['authors'][:5])
            if len(stats['authors']) > 5:
                author_list += f" and {len(stats['authors']) - 5} others"
            
            blocks.append({
                "type": "context",
                "elements": [
                    {
                        "type": "mrkdwn",
                        "text": f"ðŸ‘¥ *Contributors:* {author_list}"
                    }
                ]
            })
        
        return blocks
    
    def _create_detail_blocks(self, batch_group: BatchGroup) -> List[Dict[str, Any]]:
        """Create expandable detail blocks with pagination."""
        blocks = []
        
        if not self.config.enable_pagination or len(batch_group.messages) <= self.config.items_per_page:
            # Show all items without pagination
            blocks.extend(self._create_message_list_blocks(batch_group.messages))
        else:
            # Show first page with pagination controls
            first_page = batch_group.messages[:self.config.items_per_page]
            blocks.extend(self._create_message_list_blocks(first_page))
            
            # Add pagination info
            remaining = len(batch_group.messages) - self.config.items_per_page
            blocks.append({
                "type": "context",
                "elements": [
                    {
                        "type": "mrkdwn",
                        "text": f"ðŸ“„ Showing {len(first_page)} of {len(batch_group.messages)} items ({remaining} more)"
                    }
                ]
            })
        
        return blocks
    
    def _create_message_list_blocks(self, messages: List[BatchableMessage]) -> List[Dict[str, Any]]:
        """Create blocks for list of messages."""
        blocks = []
        
        # Sort messages by priority and timestamp
        if self.config.priority_ordering:
            sorted_messages = sorted(messages, key=lambda m: (-m.get_priority_score(), m.timestamp))
        else:
            sorted_messages = sorted(messages, key=lambda m: m.timestamp)
        
        for message in sorted_messages:
            block = self._create_message_item_block(message)
            if block:
                blocks.append(block)
        
        return blocks
    
    def _create_message_item_block(self, message: BatchableMessage) -> Optional[Dict[str, Any]]:
        """Create block for individual message item."""
        # Get appropriate icon and format based on content type
        if message.content_type == ContentType.PR_UPDATE:
            return self._create_pr_item_block(message)
        elif message.content_type == ContentType.JIRA_UPDATE:
            return self._create_jira_item_block(message)
        elif message.content_type == ContentType.ALERT:
            return self._create_alert_item_block(message)
        else:
            return self._create_generic_item_block(message)
    
    def _create_pr_item_block(self, message: BatchableMessage) -> Dict[str, Any]:
        """Create block for PR update item."""
        pr_data = message.data
        action = pr_data.get('action', 'updated')
        pr_number = pr_data.get('number', 'Unknown')
        title = pr_data.get('title', 'Untitled PR')
        author = message.author or 'Unknown'
        
        action_icons = {
            'opened': 'ðŸ†•',
            'merged': 'âœ…',
            'closed': 'âŒ',
            'approved': 'ðŸ‘',
            'ready_for_review': 'ðŸ‘€',
            'conflicts': 'âš ï¸'
        }
        
        icon = action_icons.get(action, 'ðŸ”„')
        text = f"{icon} PR #{pr_number}: {title} ({action} by @{author})"
        
        return {
            "type": "section",
            "text": {
                "type": "mrkdwn",
                "text": text
            }
        }
    
    def _create_jira_item_block(self, message: BatchableMessage) -> Dict[str, Any]:
        """Create block for JIRA update item."""
        jira_data = message.data
        ticket_key = jira_data.get('key', 'Unknown')
        summary = jira_data.get('summary', 'Untitled ticket')
        status = jira_data.get('status', {}).get('name', 'Unknown')
        author = message.author or 'Unknown'
        
        status_icons = {
            'To Do': 'ðŸ“‹',
            'In Progress': 'ðŸ”„',
            'In Review': 'ðŸ‘€',
            'Done': 'âœ…',
            'Blocked': 'ðŸš«'
        }
        
        icon = status_icons.get(status, 'ðŸ“„')
        text = f"{icon} {ticket_key}: {summary} â†’ {status} (@{author})"
        
        return {
            "type": "section",
            "text": {
                "type": "mrkdwn",
                "text": text
            }
        }
    
    def _create_alert_item_block(self, message: BatchableMessage) -> Dict[str, Any]:
        """Create block for alert item."""
        alert_data = message.data
        alert_type = alert_data.get('type', 'alert')
        severity = alert_data.get('severity', 'medium')
        description = alert_data.get('description', 'Alert triggered')
        
        severity_icons = {
            'critical': 'ðŸš¨',
            'high': 'ðŸ”´',
            'medium': 'ðŸŸ¡',
            'low': 'ðŸŸ¢'
        }
        
        icon = severity_icons.get(severity, 'âš ï¸')
        text = f"{icon} {alert_type.title()}: {description} ({severity} priority)"
        
        return {
            "type": "section",
            "text": {
                "type": "mrkdwn",
                "text": text
            }
        }
    
    def _create_generic_item_block(self, message: BatchableMessage) -> Dict[str, Any]:
        """Create block for generic message item."""
        title = message.data.get('title', 'Update')
        author = message.author or 'Unknown'
        
        return {
            "type": "section",
            "text": {
                "type": "mrkdwn",
                "text": f"ðŸ“„ {title} (@{author})"
            }
        }
    
    def _create_action_blocks(self, batch_group: BatchGroup) -> List[Dict[str, Any]]:
        """Create action buttons for batch message."""
        blocks = []
        
        # Create action buttons
        buttons = []
        
        # View Details button (expandable)
        if len(batch_group.messages) > self.config.items_per_page:
            details_btn = self._interactive_builder.create_show_details_button(
                batch_group.id, "batch"
            )
            buttons.append(details_btn)
        
        # Thread Discussion button
        if self.config.enable_threading:
            from .interactive_elements import ActionType
            thread_btn = self._interactive_builder.create_button(
                text="ðŸ’¬ Thread Discussion",
                action_type=ActionType.CUSTOM_ACTION,
                resource_id=batch_group.id,
                metadata={"action": "start_thread"}
            )
            buttons.append(thread_btn)
        
        if buttons:
            blocks.append({
                "type": "actions",
                "elements": buttons
            })
        
        return blocks
    
    def _create_fallback_text(self, batch_group: BatchGroup, stats: Dict[str, Any]) -> str:
        """Create fallback text for accessibility."""
        header = self._create_summary_header(batch_group, stats)
        
        content_summary = []
        for content_type, count in stats['content_types'].items():
            content_summary.append(f"{count} {content_type.replace('_', ' ')}")
        
        fallback_parts = [
            header,
            f"Content: {', '.join(content_summary)}",
            f"Contributors: {', '.join(stats['authors']) if stats['authors'] else 'None'}"
        ]
        
        return "\n".join(fallback_parts)


# Global batcher instance
default_message_batcher = MessageBatcher()